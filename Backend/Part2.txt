Question 1 : How would you handle memory leaks in Node.js?
1ï¸âƒ£ Understand Common Causes
Memory leaks in Node.js usually happen due to:
      ðŸ” Global variables that are never cleared
      ðŸ“¦ Large objects kept in memory (arrays, caches growing infinitely)
      ðŸŽ§ Unremoved event listeners
      â³ Timers not cleared (setInterval without clearInterval)
      ðŸ”„ Closures holding references to unused objects
      ðŸ—ƒ Unclosed resources (DB connections, file handles, sockets)

2ï¸âƒ£ Detect Memory Leaks
ðŸ“Š Monitor Memory Usage
Use built-in tools:
      console.log(process.memoryUsage());

Key metrics:
    heapUsed , heapTotal , rss
If heapUsed keeps growing without stabilizing â†’ possible leak.

ðŸ” Use Profiling Tools

Chrome DevTools (node --inspect)
Heap snapshots
Allocation timeline
clinic.js
heapdump
node --trace-gc

node --inspect app.js
Then open chrome://inspect in Chrome.

â€œTo handle memory leaks in Node.js, I first monitor memory usage using process.memoryUsage() and profiling tools like
heap snapshots. I look for continuously growing heap usage. Common causes include global variables, unremoved event
listeners, large in-memory caches, and unclosed resources. I fix leaks by removing unused references, clearing timers,
limiting cache size, and properly closing connections. I also use streaming and proper architecture patterns to prevent 
excessive memory consumption.â€

---------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------
Question 2 : Explain streams. When would you use them?
In Node.js, streams are objects that let you read or write data in small chunks instead of loading everything into memory
at once.
Instead of:
fs.readFile()  // Loads entire file into memory

Streams allow
fs.createReadStream()  // Reads file piece by piece
So streams are used for handling large data efficiently.

âœ… Why Streams Are Important
Without streams:
      Entire file/data loads into memory
      High memory usage
      Poor performance for large files

With streams:
      Process data chunk-by-chunk
      Low memory usage
      Faster and scalable
      Supports backpressure handling

âœ… Types of Streams in Node.js
There are 4 types:
1ï¸âƒ£ Readable Stream
Used to read data
Example: fs.createReadStream()

2ï¸âƒ£ Writable Stream
Used to write data
Example: fs.createWriteStream()

3ï¸âƒ£ Duplex Stream
Readable + Writable
Example: TCP sockets

4ï¸âƒ£ Transform Stream
Duplex stream that modifies data on the fly . 
Example: Compression (gzip)

âœ… Example
const fs = require('fs');
const readStream = fs.createReadStream('input.txt');
const writeStream = fs.createWriteStream('output.txt');
readStream.pipe(writeStream);

âœ… When Would You Use Streams?
ðŸ“‚ 1. Large File Processing
Video files , Log files , CSV files (millions of rows)
Instead of loading a 2GB file into memory.

ðŸŒ 2. Handling HTTP Requests & Responses . In Node.js, request and response objects are streams.
When uploading/downloading files.

ðŸ“¦ 3. Real-time Data Processing
Chat applications , Live feeds , Data pipelines

ðŸ—œ 4. Data Transformation
Compressing files (gzip) , Encrypting/decrypting data, Parsing data

âœ… What is Backpressure?
Backpressure happens when:
      Data is produced faster than it can be consumed.
Streams handle this automatically using:
.pipe()
Internal buffering
This prevents memory overflow.

â€œStreams in Node.js allow us to process data in chunks rather than loading everything into memory. They improve performance
and reduce memory usage, especially when working with large files or real-time data. Node.js provides Readable, Writable,
Duplex, and Transform streams. I would use streams when handling large file uploads/downloads, processing big datasets, or
building real-time applications where efficient memory usage is important.â€

// Practical 
1ï¸âƒ£ Readable Stream
ðŸ‘‰ Read a large file in chunks
// readable.js
const fs = require('fs');

const readStream = fs.createReadStream('input.txt', {
  encoding: 'utf8',
  highWaterMark: 16 // 16 bytes per chunk (small for demo)
});

readStream.on('data', (chunk) => {
  console.log('Chunk received:');
  console.log(chunk);
});

readStream.on('end', () => {
  console.log('Finished reading file.');
});

readStream.on('error', (err) => {
  console.error('Error:', err);
});

2ï¸âƒ£ Writable Stream
ðŸ‘‰ Write data to a file in chunks

// writable.js
const fs = require('fs');

const writeStream = fs.createWriteStream('output.txt');

writeStream.write('Hello\n');
writeStream.write('This is a writable stream example.\n');
writeStream.write('Writing data in chunks.\n');

writeStream.end(); // must call end()

writeStream.on('finish', () => {
  console.log('Finished writing to file.');
});

3ï¸âƒ£ Duplex Stream
ðŸ‘‰ Create a simple custom duplex stream

// duplex.js
const { Duplex } = require('stream');

const duplexStream = new Duplex({
  write(chunk, encoding, callback) {
    console.log('Writing:', chunk.toString());
    callback();
  },

  read(size) {
    this.push('Hello from duplex stream!\n');
    this.push(null); // end
  }
});

duplexStream.on('data', (chunk) => {
  console.log('Reading:', chunk.toString());
});

duplexStream.write('Test Data');
duplexStream.end();

4ï¸âƒ£ Transform Stream
ðŸ‘‰ Modify data while passing through
Example: Convert text to uppercase

// transform.js
const { Transform } = require('stream');

const upperCaseTransform = new Transform({
  transform(chunk, encoding, callback) {
    const upperCased = chunk.toString().toUpperCase();
    callback(null, upperCased);
  }
});

process.stdin
  .pipe(upperCaseTransform)
  .pipe(process.stdout);

Now type something and press Enter â†’ it prints UPPERCASE.
âœ” Reads input
âœ” Transforms it
âœ” Outputs modified data

==================================================================================================================
==================================================================================================================
Question 3 : What happens internally when you use async/await? 
Answer : "async/await is syntactic sugar over Promises. Internally, an async function always returns a Promise. When await 
is encountered, JavaScript pauses the function execution, waits for the Promise to resolve, and resumes execution using the 
microtask queue."

When you write:

async function example() {
  return 42;
}

Internally JavaScript converts it to:

function example() {
  return Promise.resolve(42);
}

Every async function always returns a Promise
Even if you return a normal value

Example : async function test() {
  console.log("Start");

  const result = await Promise.resolve("Hello");

  console.log(result);
  console.log("End");
}

Internally:
      1. Function starts executing synchronously
      2. "Start" prints immediately
      3. When it hits await:
            1. It pauses execution
            2. Registers the rest of the function as a .then() callback
      4. Control returns to the event loop
      5. When Promise resolves:
            1. The continuation runs inside the microtask queue

3ï¸âƒ£ Under the Hood (Desugared Version)

This:
      const result = await somePromise;

Is roughly equivalent to:
      somePromise.then(result => {
        // remaining code
      });

So await is basically cleaner .then() chaining.

6ï¸âƒ£ Does await Block the Thread?
âŒ No.
      It does NOT block the Node.js thread.
      It only pauses the async function.
      Other requests can still be processed.
      Thatâ€™s why Node.js remains non-blocking.



==================================================================================================================
==================================================================================================================
Question 4 : How do you handle centralized error handling in Express?
In express 5 , whatever written below works fine . But But , older version of express 4 unable to catch async function
error , so to handle that , we need to manually call next() method with thrown error to catch it . 
More and most professional way is the second one . 

Answer :  Basic Implementation 
import express from "express";
const app = express();
const port = 3000;

const catchException = (err, req, res, next) => {
  console.log("coming inside catchException");
  return res.status(500).json({
    message: "INTERNAL SERVER ERROR",
    error: err.message,
  });
};

app.get("/testing", (req, res) => {
  throw new Error("This is a test error");
});

app.use(catchException);

app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});

1ï¸âƒ£ Why Centralized Error Handling?
Without centralized handling:
      Try/catch everywhere âŒ
      Duplicate response logic âŒ
      Inconsistent error formats âŒ
      Hard to log and monitor âŒ

Centralized handling gives:
      âœ” Clean controllers
      âœ” Consistent error responses
      âœ” Single place for logging
      âœ” Easy monitoring (Sentry, etc.)

2ï¸âƒ£ How Express Handles Errors

In Express.js, an error-handling middleware is defined like this:
(err, req, res, next)
âš ï¸ The 4 parameters are mandatory.
Thatâ€™s how Express knows itâ€™s an error middleware.


Part 2 : So in express 4 we are unable to catch async function error , but in express 5 it is possible . 
To handle this case , we have to write catch in every controller callback like below : 

app.get("/testing", (req , res , next)=>{
      controllerFunction(req , res).catch((err)=>{   // need to write this in every route , because without calling next() method global exception handler won't get trigger . 
            next(err) 
      })
} );

To solve this we wrap this task in seperate function and then call that wrapper function directly , like below . 

const catchAsyncError = (fn) => {
  return (req, res, next) => {
    fn(req, res, next).catch((err) => {
      next(err);
    });
  };
};

It will take controller function as a parameter and return a function , inside that function it has put catch method . 
Now in our current case , we are sending same error to our customer , but need to send seperate error in different case 
to make it more better , we should create seperate AppError class that will extend Error class . 


====> Complete Implementation <=============

import express from "express";
const app = express();
const port = 3000;

const globalExceptionHandler = (err, req, res, next) => {
  const sendErrorDev = (err, res) => {
    res.status(err.statusCode).json({
      status: err.status,
      error: err,
      message: err.message,
      stack: err.stack,
    });
  };

  const sendErrorProd = (err, res) => {
    res.status(err.statusCode).json({
      status: err.status,
      message: err.message,
    });
  };

  err.statusCode = err.statusCode || 500;
  err.status = err.status || "error";

  if (process.env.NODE_ENV === "development") {
    sendErrorDev(err, res);
  } else {
    sendErrorProd(err, res);
  }
};

const catchAsyncError = (fn) => {
  return (req, res, next) => {
    fn(req, res, next).catch((err) => {
      next(err);
    });
  };
};

const controller = async (req, res) => {
  //   throw new Error("This is a test error");
  throw new AppError("User not found", 404);
};

class AppError extends Error {
  constructor(message, statusCode) {
    super(message);
    this.message = message;
    this.status = `${statusCode}`.startsWith("4") ? "fail" : "error";
    this.statusCode = statusCode;
    this.isOperational = true; // Used to distinguish known errors from unknown bugs

    Error.captureStackTrace(this, this.constructor);
  }
}

app.get("/testing", catchAsyncError(controller));

app.use(globalExceptionHandler);

app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});


=======================================================================================================================
=======================================================================================================================
Question 5 : How to make response generic format , it should be same format everywhere ? Respone standardization
Answer : âœ… Best Practice Approach
There are 2 professional ways to do this:
      1ï¸âƒ£ Create a custom response helper
      2ï¸âƒ£ Override res.json() globally

Approach 1 (Recommended): Response Helper Utility
--Step 1: Create response utility

// utils/responseHandler.js
const sendResponse = (res, {
  statusCode = 200,
  status = "SUCCESS",
  message = "",
  data = null
}) => {
  return res.status(statusCode).json({
    STATUS: status,
    MESSAGE: message,
    "OB-API": data
  });
};

module.exports = sendResponse;

-- Step 2: Use it in routes

const sendResponse = require('./utils/responseHandler');

app.get('/user', (req, res) => {
  const user = { id: 1, name: "John" };

  sendResponse(res, {
    statusCode: 200,
    message: "User fetched successfully",
    data: user
  });
});

---Step 3: Use it in error handler
app.use((err, req, res, next) => {
  sendResponse(res, {
    statusCode: err.statusCode || 500,
    status: "FAILED",
    message: err.message,
    data: null
  });
});

ðŸ”¹ Approach 2: Override res.json() (Advanced)
If you want FULL control so no one can bypass it:

app.use((req, res, next) => {
  const oldJson = res.json;

  res.json = function (data) {
    const formatted = {
      STATUS: "SUCCESS",
      MESSAGE: "Request successful",
      "OB-API": data
    };

    return oldJson.call(this, formatted);
  };

  next();
});








