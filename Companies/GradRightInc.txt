
***************************1. How to handle event loop to not get blocked ?

ğŸ” Why the Node.js event loop gets blocked

Node.js runs JavaScript on a single thread.
If that thread is busy doing CPU-heavy or synchronous work, the event loop canâ€™t process:

incoming requests

timers

I/O callbacks

â¡ï¸ Result: your app â€œfreezesâ€ or becomes slow.

âŒ Common things that block the event loop
1. Synchronous operations
fs.readFileSync('big.txt'); // âŒ blocks

2. Heavy CPU calculations
while (true) {} // âŒ blocks everything

3. Large JSON parsing
JSON.parse(hugeString); // âŒ can block

4. Bad async patterns
for (let i = 0; i < 1e9; i++) {
  await doSomething(); // âŒ serial + slow
}

âœ… How to prevent event loop blocking

1ï¸âƒ£ Use async, non-blocking APIs

Always prefer async versions.

// âœ… Non-blocking
fs.readFile('big.txt', (err, data) => {});

or with promises:

await fs.promises.readFile('big.txt');

2ï¸âƒ£ Offload CPU-heavy work
âœ” Use Worker Threads (best for CPU tasks)
const { Worker } = require('worker_threads');

new Worker('./worker.js', {
  workerData: bigData
});

âœ” Good for:
encryption
image processing
data transformation

3ï¸âƒ£ Use child processes (for isolation)
const { fork } = require('child_process');
fork('heavyTask.js');

âœ” Useful for:
background jobs
long-running tasks

4ï¸âƒ£ Break large tasks into chunks

Yield back to the event loop.

function processChunk(items) {
  const chunk = items.splice(0, 1000);

  chunk.forEach(doWork);

  if (items.length) {
    setImmediate(() => processChunk(items)); // âœ… yields
  }
}

6ï¸âƒ£ Use streams for large data
fs.createReadStream('big.txt')
  .pipe(fs.createWriteStream('copy.txt'));

âœ” Prevents loading everything into memory.

âš ï¸ Golden rule
If it takes more than ~10â€“20ms of CPU time, donâ€™t run it on the main thread.


********************************* 2. What is worker thread ***********************************************
A worker thread is:
A separate JavaScript thread with its own event loop, own call stack, and own V8 instance

When you create a worker thread:
It runs in parallel to the main thread
It does not block the main event loop
It can execute CPU-heavy code safely

Think of it like this:

Main Thread (Event Loop)
 â”œâ”€â”€ handles HTTP requests
 â”œâ”€â”€ timers
 â”œâ”€â”€ async I/O
 â””â”€â”€ delegates heavy work

Worker Thread
 â””â”€â”€ runs heavy CPU logic

2ï¸âƒ£ Does a worker thread execute code in parallel with the event loop?
âœ… YES â€” truly in parallel

This is real parallelism, not async trickery.

If you have:
1 main thread
1 worker thread

And your CPU has at least 2 cores:
â¡ï¸ both run at the same time.

CPU Core 1 â†’ Main Event Loop
CPU Core 2 â†’ Worker Thread

So while the worker is crunching numbers:
the main thread keeps serving requests
timers still fire
sockets still work

3ï¸âƒ£ Why async/await alone is NOT enough

This is a common misunderstanding.

await heavyComputation(); // âŒ still blocks

Why?
async/await only helps with I/O
CPU work still runs on the same thread

So:
async â‰  parallel
worker threads = parallel

4ï¸âƒ£ How a worker thread actually works (internally)

When you do:
new Worker('./worker.js')

Node:
Spawns a new thread
Starts a new JS runtime
Loads worker.js
Runs it independently

Communication happens via:
postMessage()
SharedArrayBuffer (advanced)


5ï¸âƒ£ Simple example (image processing)
Main thread
const { Worker } = require('worker_threads');

function resizeImage(imageBuffer) {
  return new Promise((resolve, reject) => {
    const worker = new Worker('./imageWorker.js', {
      workerData: imageBuffer
    });

    worker.on('message', resolve);
    worker.on('error', reject);
  });
}

#Worker thread
const { workerData, parentPort } = require('worker_threads');
const result = heavyImageProcessing(workerData);
parentPort.postMessage(result);


ğŸ“Œ While heavyImageProcessing() runs:
event loop stays free
requests continue
app stays responsive

6ï¸âƒ£ Are worker threads the same as child processes?
Feature	          Worker Thread	                Child Process
Memory	          Shared (optional)	            Separate
Startup cost	    Low	                          High
Communication	    Fast	                        Slower (IPC)
Best for	        CPU tasks	                    Isolation

7ï¸âƒ£ How many worker threads should you use?

Rule of thumb:
maxWorkers = number_of_CPU_cores - 1

Why?
Leave one core for the event loop
Too many workers = context switching overhead
You can get CPU count:

const os = require('os');
os.cpus().length;

8ï¸âƒ£ When should you NOT use worker threads?

âŒ Donâ€™t use workers for:

database calls
HTTP requests
file I/O

Those are already async & non-blocking.

9ï¸âƒ£ Mental model (remember this ğŸ‘‡)

Node.js is single-threaded for I/O, but multi-threaded for CPU if you allow it
Workers are how you â€œunlockâ€ multiple cores.


***************************************** Child Process ****************************************************
A child process in Node.js is a way for your app to run another program in the background without blocking itself.

First, a tiny idea: what is a â€œprocessâ€?
When you run a program on your computer, the computer starts a process.

Example:
You open Chrome â†’ Chrome runs as a process
You run node app.js â†’ Node.js runs as a process

So a process = a running program

What is Node.js doing?

---> When you start a Node.js app:

node app.js

Node.js runs your code in one main process.
This main process:
Handles requests
Runs your JavaScript code
Uses one CPU core by default

A child process is simply:
A new program started by your Node.js program

Very simple mental model ğŸ§ 
Main Node App (Parent)
        |
        |---- Child Process (extra helper)
        |---- Child Process (another helper)

Each child:
Runs separately
Can do heavy work
Wonâ€™t block the main app

Types of child processes (just names for now)
Node.js gives you a few ways to create them:
exec() â†’ run simple commands
spawn() â†’ stream data (better for large output)
fork() â†’ run another Node.js file

1ï¸âƒ£ exec â€“ â€œRun a command and give me the resultâ€
What itâ€™s for
Use exec when:
The command is small
You want the final output as a string

Real-life analogy

ğŸ‘‰ â€œRun this command and tell me what it prints.â€

Simple example
const { exec } = require("child_process");

exec("node -v", (error, stdout, stderr) => {
  console.log("Node version is:", stdout);
});

What happens step-by-step

Your Node app starts
It creates a child process
That process runs node -v
The entire output is returned at once

Important thing to know âš ï¸
Output is stored in memory
Not good for big output

âœ”ï¸ Good for:
Checking versions
Running small commands

2ï¸âƒ£ spawn â€“ â€œRun a command and show output little by littleâ€
What itâ€™s for

Use spawn when:
Output is large
You want data as it happens

Real-life analogy

ğŸ‘‰ â€œRun this command and keep talking while it runs.â€

Simple example
const { spawn } = require("child_process");

const child = spawn("node", ["-v"]);

child.stdout.on("data", (data) => {
  console.log("Output:", data.toString());
});

What happens step-by-step
Node creates a child process
The command starts running
Output comes in chunks
You receive data piece by piece

*******3ï¸âƒ£ fork â€“ â€œRun another Node.js fileâ€
What itâ€™s for
Use fork when:
You want to run another Node.js script
You want to send messages back and forth

Real-life analogy

ğŸ‘‰ â€œRun this Node.js file and letâ€™s talk to each other.â€

Simple example
parent.js
const { fork } = require("child_process");

const child = fork("child.js");

child.on("message", (msg) => {
  console.log("From child:", msg);
});

child.send("Hello child!");

child.js
process.on("message", (msg) => {
  console.log("From parent:", msg);
  process.send("Hello parent!");
});

What happens
Parent starts
Parent forks another Node.js file
They can talk using messages
Heavy work can run in the child

ğŸ§  Beginner rule of thumb
Small command â†’ exec
Big / long task â†’ spawn
Another Node.js file â†’ fork

One-line summary

exec waits for everything, spawn listens while it runs, and fork talks to another Node.js program.

Must Read Article :  https://dev.to/wallacefreitas/understanding-worker-threads-and-child-processes-52nj

***************** Difference between child process and worker threads ****************************************
Choosing Between Worker Threads and Child Processes

Feature	                          Worker Threads	                              Child Processes
Memory Sharing	                  Supported via SharedArrayBuffer	              Not supported
Task Isolation	                  Shared environment, less isolated	            Fully isolated
Use Case	                        CPU-intensive tasks in JavaScript	            System-level tasks or external code
Overhead	                        Lower (same process)	                        Higher (separate processes)
Communication	                    Via message passing, faster	                  Via IPC, slower
Supported Languages	              JavaScript/Node.js only	                      Any scripting or system-level language
Startup Time	                    Faster	                                      Slower
Error Containment	                Less contained, can crash the process	        Fully contained, isolated failures


****************************************************************************************************************************
*************************************************** Memory Leak In Node Application ***************************************

Best Article : https://medium.com/@amirilovic/how-to-find-production-memory-leaks-in-node-js-applications-a1b363b4884f 
              https://github.com/felixge/node-memory-leak-tutorial
              In Github , also there is one repo called 'memory-lead-node' 


1ï¸âƒ£ What is a memory leak in Node.js?

A memory leak happens when:
Memory is allocated
But never released
Even though the application no longer needs it

In Node.js:
Garbage Collection (GC) does exist
Leaks happen when objects are still reachable
GC cannot free reachable objects

âš ï¸ If something is referenced, it is not garbage.

2ï¸âƒ£ Why memory leaks happen in Node.js
ğŸ”¹ Single long-running process
Node servers often run for days or weeks
Small leaks accumulate over time
Restart hides problems temporarily

ğŸ”¹ V8 Garbage Collector is reference-based
GC frees only unreachable objects
Any reference from a GC root keeps memory alive

ğŸ”¹ JavaScript makes leaks easy
Closures , Globals , Dynamic object growth , Hidden references .

3ï¸âƒ£ GC Roots (very important concept)

Objects are never freed if reachable from:
Global variables , Module-level variables , Active closures , Event listeners , Timers , Caches
These are called GC roots.

4ï¸âƒ£ Common ways memory leaks happen in Node.js ?

4.3 Closures retaining large objects
function handler(req) {
  const largeData = loadBigData();

  return () => {
    console.log(req.url);
  };
}

Why it leaks:
Closure keeps largeData alive
Even if not used anymore
Very common in:
Event handlers
Middleware
Async callbacks

4.4 Event listeners not removed
emitter.on("data", handler);

Why it leaks:
Listener holds references
Never removed â†’ never GCâ€™d

Examples:
WebSocket connections
Process events
Custom EventEmitters
Node even warns:

MaxListenersExceededWarning

-- 4.5 Timers & intervals not cleared
setInterval(() => {
  doSomething();
}, 1000);

Why it leaks:
Timer keeps callback alive
Callback keeps scope alive

Examples:
Polling logic
Background tasks
Retry loops

4.6 Promises that never resolve or reject
new Promise(() => {});

Why it leaks:
Promise stays pending forever
Captured variables never released

5ï¸âƒ£ Signs you might have a memory leak
Heap size keeps growing
GC runs more frequently
App slows down over time
Container OOMKills
Requires periodic restarts
Heap snapshots show increasing retained size

8ï¸âƒ£ Summary (one-liner)
Node.js memory leaks happen when objects remain reachable from long-lived references such as globals, closures, listeners,
timers, or caches.


************************* How to debug Memory Leak issue in Node ****************************************

1. We can run node application in inspect mode by node --inspect app.js . 

ğŸ§  1. Node.js uses the same JS engine as Chrome
Node.js is built on V8, the same JavaScript engine that Chrome (and Chromium-based browsers) use. Because of that, V8 
exposes debugging and profiling functionality in a standard way. These features â€” including heap snapshots â€” were originally
developed for browsers, but Node.js exposes them too.

ğŸ›  2. How the â€œbrowserâ€ sees a Node.js app

When you run Node with:

node --inspect index.js

or

node --inspect-brk index.js

Node starts an Inspector agent. This agent:
Listens on a WebSocket port (default 9229)
Speaks the Chrome DevTools Protocol (CDP)
Exposes debug and profiling features (like heap snapshots) via that protocol.

Now go to your browser and open:

chrome://inspect

You will see your Node.js process listed as a â€œremote target.â€ When you click Inspect, your browser opens Chrome DevTools,
but connected to your Node process instead of a web page.

So even though itâ€™s a browser window, itâ€™s really acting as a remote debugger UI talking to Node.

ğŸ§¾ 3. Heap snapshots arenâ€™t â€œfrom the browserâ€ â€” theyâ€™re from Node

Inside DevTools, youâ€™ll see a Memory tab. When you click Take heap snapshot, what happens is:

1. DevTools (browser) sends a CDP command over WebSocket to Node/V8.
2. Node/V8 generates a snapshot of its own memory heap.
3. That snapshot file is sent back to DevTools.
4. DevTools displays it in the browser UI for you to explore.

So the browser isnâ€™t magically inspecting Nodeâ€™s memory by itself â€” itâ€™s using DevTools protocol to ask Nodeâ€™s V8 to produce a snapshot and then visualize it.

ğŸ”„ Why this is useful for debugging leaks

Heap snapshots show you:
All JS objects currently in memory
Their sizes
The paths that keep them alive (whatâ€™s retaining them)

You use this by:
1. Taking a snapshot at an initial point
2. Triggering some app behavior you think leaks memory
3. Taking another snapshot
4. Comparing them to see what objects increased or didnâ€™t get freed
5. Investigating whatâ€™s holding references to those objects


*************************************************************************************************************************
Problem Statement : Think of system like OYO which have thousands of agents and huge user base . If user will do some 
search based on some parameters , how should it get optimized . Because when i fetch all agents and then process 
all agent data , it will take time and processing cost will be also there . What should be good solution of this ?

Answer : You should never scan everything.

Instead:

Move filtering, ranking, and searching as close to the data as possible
Use indexing, pre-aggregation, and search systems .

3. High-level ideal solution
ğŸ”‘ Key ideas
Pre-index agent data
Use a Search Engine (not just DB)
Filter first â†’ Rank later
Cache popular queries
Asynchronous updates

4. Realistic architecture (OYO-like)
1ï¸âƒ£ Use a Search Engine (VERY IMPORTANT)

Use:
Elasticsearch / OpenSearch / Solr

Why?
Designed for:
fast filtering
scoring
ranking
geo search
faceted search

Each agent/listing is indexed like:

{
  "agentId": 123,
  "city": "Bangalore",
  "price": 1500,
  "rating": 4.3,
  "amenities": ["wifi", "ac"],
  "availability": true,
  "geo": { "lat": 12.97, "lon": 77.59 }
}

2ï¸âƒ£ Indexing strategy (CRUCIAL)

Create indexes on:

destination / city , price range , rating , availability , geo location

So search becomes:

city = Bangalore
AND price between 1000â€“2000
AND rating >= 4
ORDER BY relevance_score

âš¡ This query runs in milliseconds, not seconds.

3ï¸âƒ£ Filtering vs Ranking

Step 1 â€“ Filter (cheap operation)

City, Price range, Availability

Step 2 â€“ Rank (scoring)

Best price, Best rating, Distance, Personalized score

Example scoring formula:

score = (0.5 * rating)
      + (0.3 * price_score)
      + (0.2 * distance_score)

This ranking happens inside search engine, not app code.

6. Caching (huge win)
Types of cache:
ğŸ”¹ Query Cache
Popular searches like:
"Hotels in Delhi under 2000"

Store:

Redis / Memcached

ğŸ”¹ Result Cache

Cache top results for:
city + price bucket + date

TTL:
Short (5â€“10 minutes)

â€œI would not fetch all agents and filter in application.
Instead, I would index agent data in a search engine like Elasticsearch with proper indexes on city, price, rating, and 
availability.
User queries are executed directly on the search index, which filters and ranks results efficiently.
Only the top N agent IDs are fetched and enriched from DB.
Additionally, I would use caching for popular searches and async updates to keep the index fresh.
This approach is scalable, low-latency, and production-ready.â€












