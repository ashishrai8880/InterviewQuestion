

Group or Namespaces -> It basically seperate every groups or enviroment . 

Namespace ---->    Nginx(or any docker image)  ->  POD  ->  Deployment  -> Service  ->  User . 

Commands to create above resource 

1. kubectl get namespace or kubectl get ns
2. kubectl get pods
3. kubectl get pods -n <namespace-name>   -> it will give all pods inside namespace 
4. kubectl create namespace/ns nginx     ->  it will create namespace
5. kubectl run nginx --image=nginx     -> it will run nginx , it will pull from docker hub . by default it always create pods inside default namespace
6. kubectl run nginx --image=nginx -n nginx -> it will create and run pod inside namespace nginx
7. kubectl delete pod nginx -n nginx
8. kubectl delete ns nginx 

--------------------------------------------------------- Creating resource by manifest files -------------------------------------------------------------------
namespace.yml file 

vim namespace.yml
// ----------STARTS

kind: Namespace
apiVersion: v1
metadata:
  name: nginx

// -------ENDS

COMMAND : kubectl apply -f namespace.yml 

2. pod.yml
vim pod.yml
// ----------------- STARTS

kind: Pod
apiVersion: v1
metadata:
  name: nginx-pod
  namespace: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80

// ---------- ENDS

COMMAND : kubectl apply -f pod.yml

3. deployment.yml file

// ----------- STARTS

kind: Deployment
apiVersion: apps/v1
metadata:
  name: nginx-deployment
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx-dep-pod
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80

// --------- ENDS

COMMAND : kubectl apply -f deployment.yml . 
kubectl scale deployment/nginx-deployment -n nginx --replicas = 5   -> This command will automatically create 5 POD

-------------------------------------------------------------------------- Theory -----------------------------------------------------------------------------

1. What is a Deployment?

In Kubernetes, a Deployment is a higher-level abstraction that manages the lifecycle of your application. It allows you to:
Deploy applications and ensure they are running correctly.
Scale your application easily by adjusting the number of replicas (copies of your application).
Roll out updates to your application in a controlled and predictable manner (e.g., upgrading your app without downtime).
Rollback to a previous version in case something goes wrong with an update.
When you use a Deployment, Kubernetes ensures that your application is always running the right number of replicas and that any changes to the app
(e.g., rolling updates or rollbacks) happen smoothly.

What Does the deployment.yml File Do?

Your deployment.yml file defines the configuration for your Kubernetes Deployment. Here’s a breakdown of each part:

kind: Deployment          # Specifies the type of object you are creating. "Deployment" in this case.
apiVersion: apps/v1       # This defines the API version for the Deployment object.
metadata:
  name: nginx-deployment  # The name of the deployment.
  namespace: nginx        # The namespace in which the deployment will live. Here it's set to 'nginx'.
spec:
  replicas: 2             # Number of pod replicas (instances) you want to run. Kubernetes will maintain this count.
  selector:
    matchLabels:
      app: nginx          # A label selector that determines which pods belong to this Deployment.
  template:
    metadata:
      labels:
        app: nginx        # These labels are applied to the pods created by the deployment.
    spec:
      containers:
      - name: nginx
        image: nginx:latest  # The Docker image to use for the container. In this case, it’s Nginx.
        ports:
        - containerPort: 80  # Exposes port 80 on the container to be accessible.

Explaining Key Concepts
1. Deployment vs Pod

Pod: A Pod is the smallest unit of execution in Kubernetes. It can run one or more containers that share the same network and storage. However, Pods are not 
self-healing, meaning if a pod fails, it won't be automatically restarted or replaced.

Deployment: A Deployment is a higher-level object that manages Pods. It ensures that the specified number of Pods are always running and can handle tasks like 
scaling, rolling updates, and rollbacks. If a Pod goes down, the Deployment will automatically create a new one to maintain the desired state.

In short: A Deployment manages Pods and ensures that they are running properly.

2. Why Use a Deployment Instead of a Pod?
Scalability: With a Deployment, you can easily scale the number of Pods up or down (by changing the replicas field). This is much harder to do with just a single Pod.
High Availability: If a Pod in a Deployment crashes, Kubernetes will automatically recreate it to maintain the desired number of replicas.
Rollouts: A Deployment allows for rolling updates, meaning you can update your app with minimal downtime.

ReplicaSet and StatefulSet
Before jumping into ReplicaSets and StatefulSets, let's define them:

ReplicaSet
Definition: A ReplicaSet is a lower-level object in Kubernetes that ensures a specified number of identical Pods are running at any given time.
Purpose: It manages the scaling of Pods and ensures there is always the right number of replicas running, but it does not handle updates or version control.
ReplicaSets are usually managed by a Deployment.

Key Use Case: If you need to maintain a certain number of Pods (for example, if one Pod crashes), a ReplicaSet ensures that the Pods are recreated.
In practice, you rarely create ReplicaSets directly; instead, Deployments manage ReplicaSets for you. When you define a Deployment, Kubernetes automatically 
creates a ReplicaSet behind the scenes.

StatefulSet
Definition: A StatefulSet is like a Deployment but specifically designed for managing stateful applications.

Purpose: StatefulSets are used when your Pods need persistent storage (e.g., databases) or a unique identity. It helps with scaling, upgrading, and maintaining 
the order of Pods.
Key Use Case: For applications like databases (e.g., MySQL, MongoDB), where each Pod should have its own persistent storage and should maintain its identity across restarts.

Summary of Key Components
Deployment: A higher-level object that manages Pods, ensures replicas are running, and handles updates/rollbacks.
ReplicaSet: Ensures a specific number of Pods are running but doesn't manage updates/rollouts. Usually managed by Deployments.
StatefulSet: Similar to Deployment, but for stateful applications that require unique identities or persistent storage.

Why Do We Need deployment.yml?
A deployment.yml file is used to declare the configuration for your app's deployment, including:

The number of Pod replicas.

The Docker image used for the application.
The ports to expose.
The labels to match and select the Pods.
The rolling update strategy (for seamless updates).
This file is important because it allows Kubernetes to know how to deploy and manage your application.


-------------------------------------------------------- My OWN Notes ----------------------------------------------------------------------------
1. Replica Set : Ye bas replica bana deta hai pods k , isme rolling update , scaling pods ye sab feature nahi hai .  jitne replicas mention honge utne bana dega bas . 
2. Daemon Set : Ye ensure karta hai ki , has nodes/worker pe atleast 1 pod chal rha ho . 
3. Deployment Set : Sabse badhiya hai , isme rolling update hota hai , scaling kar sakte hai . Rolling update means , agar version update kar rhe hai to , saare pods
ka ek saath version update nahi hoga , 1-1 karke hoga , jisse downtime nahi rahega . Deployment me hum kabhi bhi number of pods scale kar sakte hai . 
4. Stateful Set : Ye PODS ki state maintain karke rakhta hai . 

Replica Set ki yml file: 
kind: ReplicaSet
apiVersion: apps/v1
metadata:
  name: nginx-replicaset
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx-rep-pod
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80

Daemon Set ki yml file ----------------------
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: nginx-daemonset
  namespace: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx-daemon-pod
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80


--------------------------------------------------------------------------- Jobs --------------------------------------------------------------
If we want to run only once task , then we can use jobs . 

kind: Job
apiVersion: batch/v1
metadata:
  name: demo-job
  namespace: nginx
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      name: demo-job-pod
      labels:
        app: batch-task
    spec:
      containers:
      - name: batch-container
        image: busybox:latest
        command: ["sh", "-c" ,"echo Hello Dosto! && sleep 10"]
      restartPolicy: Never


------------------------------------------------------------- Cron Jobs for periodic task running ---------------------------------------------------------------
kind: CronJob
apiVersion: batch/v1
metadata:
  name: minute-backup
  namespace: nginx

spec:
  schedule: "* * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          name: minute-backup
          labels:
            app: minute-backup

        spec:
          containers:
          - name: backup-container
            image: busybox
            command:
            - sh
            - -c
            - >
              echo "Backup Started" ;
              mkdir -p /backups &&
              mkdir -p /demo-data &&
              cp -r /demo-data /backups &&
              echo "Backup Completed" ;
            volumeMounts:
              - name: data-volume
                mountPath: /demo-data
              - name: backup-volume
                mountPath: /backups
          restartPolicy: OnFailure
          volumes:
            - name: data-volume
              hostPath:
                path: /demo-data
                type: DirectoryOrCreate
            - name: backup-volume
              hostPath:
                path: /backups
                type: DirectoryOrCreate


--------------------------------------------------------------- Persistent Volume and Persistent Volume Claims ------------------------------------------------------

Understanding PersistentVolume (PV) and PersistentVolumeClaim (PVC) is a key step in learning how Kubernetes handles storage. These two concepts help you manage data that should not be lost when a Pod is deleted, restarted, or rescheduled.

🧠 The Problem: Why Do We Need Persistent Storage in Kubernetes?
By default, Pods are ephemeral — which means:
If a Pod crashes or is deleted, all data inside it is lost.
Any files stored in a container's local filesystem disappear once the container is gone.
This is a huge problem for apps like:
Databases (e.g., MySQL, MongoDB)
File-based apps (e.g., WordPress)
Anything that needs to store data across Pod restarts

So, we need a way to attach reliable, persistent storage to Pods — that's where PersistentVolumes (PV) and PersistentVolumeClaims (PVC) come in.

📦 What is a PersistentVolume (PV)?
A PersistentVolume is a storage resource in your cluster. It’s like a pre-configured storage disk (e.g., from your cloud provider, a NFS share, a local disk).
Created by the cluster admin.
Kubernetes manages this volume independently of any specific Pod.

📝 Think of it as a storage unit in a storage room, already available and waiting to be used.
📑 What is a PersistentVolumeClaim (PVC)?

A PVC is a request for storage by a user (usually part of a Pod).
It specifies:
How much storage the Pod needs (e.g., 5Gi) . What kind of access it needs (e.g., read-write) .Kubernetes will bind the PVC to a suitable PV that meets the request.

📝 Think of it like a person asking for a storage locker (PVC) — Kubernetes will assign them an appropriate locker (PV).

📦 + 📑 = 📂 How PV and PVC Work Together
[ PersistentVolume (PV) ] <----bound----> [ PersistentVolumeClaim (PVC) ] <----attached to----> [ Pod ]

Admin creates a PV (or it’s dynamically created).
User creates a PVC in a manifest.
Kubernetes finds a matching PV and binds it to the PVC.
Pod uses the PVC to mount the storage.

✅ Real-Life Analogy
Imagine a public storage facility:
The storage units (PVs) are pre-created.
A customer (PVC) comes in and asks for a 100 sq. ft. unit.

The manager (Kubernetes) finds a unit that matches and assigns it to the customer.
The customer moves in and starts storing their stuff (Pod writes data).
If the customer moves to a new house (Pod is recreated), they can still access the same storage unit (persistent data remains).

📁 Example: PV + PVC + Pod
Step 1: Create a PersistentVolume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/pv1  # Only for local testing (not for production)

Step 2: Create a PersistentVolumeClaim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi

Step 3: Use the PVC in a Pod
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-container
      image: nginx
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: my-storage
  volumes:
    - name: my-storage
      persistentVolumeClaim:
        claimName: my-pvc


In this setup:
NGINX will serve files from the persistent volume.
Data written to /usr/share/nginx/html is stored on disk.
If the Pod dies or restarts — data remains.

📊 Why Are PV and PVC Important?
Feature	Benefit
Data Persistence	Keeps data even when Pods are deleted
Pod Independence	Storage is managed independently of Pods
Scalability	Works with dynamic storage provisioning
Storage Abstraction	You don’t need to know where/what the storage is
Flexibility	PVCs can request different storage classes



=========================================================================== Service YML File ========================================================================
🌐 What is a Service in Kubernetes?

In Kubernetes, a Service is an abstraction that defines how to access a set of Pods. It provides a stable endpoint (IP and port) for communicating with Pods, even if their IP addresses change.
By default, Pods in Kubernetes have ephemeral IP addresses, meaning they can change if the Pod is recreated, restarted, or rescheduled. A Service makes sure you can always access the Pods reliably.

📝 Common Use Cases for Services:
Load Balancing: A Service can load balance traffic across multiple Pods.
Discovery: Other services or Pods can discover and communicate with the Pods behind a Service using DNS.
Stability: Ensures that the IP and port to access your application are constant even if Pods are recreated.

🔥 Types of Services:
There are four types of services you can define in Kubernetes:
ClusterIP (default): Exposes the Service on a cluster-internal IP. Other Pods in the cluster can access it, but it’s not accessible externally.
NodePort: Exposes the Service on the same port on each node in the cluster. Allows external traffic to access the Service via <NodeIP>:<NodePort>.
LoadBalancer: Provisions a load balancer from your cloud provider (e.g., AWS, GCP). This is typically used for exposing your app to the external world.
ExternalName: Maps the Service to an external DNS name. It doesn’t create a proxy but simply returns the DNS name when queried.

🧰 Structure of a service.yml File

A typical service.yml defines the kind of service, metadata, and specifications. Let’s break down an example:

Example of a service.yml (for a ClusterIP service):
apiVersion: v1                    # API version, here it's the standard API for Services
kind: Service                      # This is the kind of resource (Service)
metadata:
  name: nginx-service              # The name of the service (how other Pods will reference it)
  namespace: default               # The namespace where the Service resides
spec:
  selector:                         # Selector to match the Pods to target
    app: nginx                      # Service will route traffic to Pods with the label "app: nginx"
  ports:
    - protocol: TCP                 # Communication protocol (TCP or UDP)
      port: 80                       # The port that the Service exposes on the cluster
      targetPort: 80                 # The port on the Pods to forward traffic to
  clusterIP: 10.96.0.1              # Cluster-internal IP for the Service (usually auto-assigned)

Key Components:
apiVersion: Specifies which version of the Kubernetes API the object is using (e.g., v1).
kind: Specifies that we are defining a Service.
metadata: Contains the name and namespace for the Service.
name: The name of the Service.
namespace: The namespace in which the service is created (default is default if not specified).
spec: The specification of the Service, which defines its behavior.
selector: Defines which Pods this Service should target based on their labels. The Service routes traffic to Pods that match these labels.
ports: Defines how the Service exposes ports to clients.
port: The port on which the Service will be available (internally).
targetPort: The port on the Pods that the Service will forward traffic to.
protocol: Specifies the communication protocol (usually TCP, but can be UDP).
clusterIP: The internal IP address of the Service within the Kubernetes cluster. This is automatically generated unless you specify it.

Service Types Explained:

1. ClusterIP (default):
Use case: Internal communication between Pods within the same cluster.
How it works: Kubernetes will automatically assign an internal IP (accessible within the cluster) for the Service.

Example for ClusterIP:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP

2. NodePort:
Use case: Exposes the Service on a specific port on every node in the cluster, allowing access from outside the cluster.
How it works: Kubernetes will expose the Service on a port (30000-32767 by default) on each node’s IP address. External traffic can access the Service using <NodeIP>:<NodePort>.

Example for NodePort:

apiVersion: v1
kind: Service
metadata:
  name: my-nodeport-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080  # You can specify a port number or let Kubernetes choose one
  type: NodePort

3. LoadBalancer:

Use case: Exposes the Service to the internet through a cloud provider’s load balancer.
How it works: Automatically provisions a load balancer and assigns it a public IP. This is used for exposing web services, databases, etc., to external users.

Example for LoadBalancer:

apiVersion: v1
kind: Service
metadata:
  name: my-loadbalancer-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer

4. ExternalName:
Use case: Maps the service to an external DNS name (i.e., an external service).
How it works: This type doesn’t create a proxy, but simply returns a DNS name when the Service is queried.

Example for ExternalName:

apiVersion: v1
kind: Service
metadata:
  name: my-external-service
spec:
  type: ExternalName
  externalName: my.external.service.com

🧰 Why Are Services Important?
Stable Networking: Services provide stable networking endpoints that don’t change, even if Pods are rescheduled or recreated.
Load Balancing: A Service can distribute traffic evenly across Pods, helping ensure high availability and reliable performance.
Decoupling: Services decouple the consumer (another Pod, or an external client) from the underlying Pods that provide the application, making it easier to manage deployments and scaling.

Discovery: Kubernetes automatically manages DNS for Services, allowing Pods to discover and connect to other services by name (e.g., my-service.default.svc.cluster.local).

🧠 Summary of Service Components
Field	Description
apiVersion	API version for the resource (usually v1)
kind	Defines the type of resource (Service)
metadata	Name and labels for the Service
spec	Specification of the Service behavior
selector	Matches Pods to this Service based on labels
ports	Defines the port mappings for the Service
type	Type of service (ClusterIP, NodePort, LoadBalancer, ExternalName)

⚡ Quick Recap
A Service provides a stable endpoint to access your Pods.
It decouples the internal application logic from the Pods, making it easier to manage scaling and networking.

Types of Services:

ClusterIP: Internal access (default).
NodePort: Expose your service on a port on every node.
LoadBalancer: Expose your service via a cloud provider’s load balancer.
ExternalName: Redirect to an external service.


==================================================================== Own Notes of service yml file ===========================================================
After completing service file . Run command 
kubectl apply -f service.yml . 

and then run below command to forward port to public user . Since in Kind Cluster everything running inside docker container . Each node is itself a docker container . 

kubectl port-forward service/nginx-service -n nginx 80:80 --address=0.0.0.0

If not work then run above command with sudo -E . 


==========================================================================================================================
================================================ Ingress =================================================================

🧠 What is Ingress?

Ingress is a Kubernetes object that manages external access to services inside your cluster—typically HTTP or HTTPS traffic.
Think of it like a smart gate to your Kubernetes cluster that decides:

Who can come in
Where their request should go
How traffic is handled (e.g. HTTPS, redirects, rules)

🎯 Real-life Analogy

Imagine you run a mall (your Kubernetes cluster) with many shops (your services).
Each shop has its own back door (ClusterIP/Service)
But customers can't go to those directly.
So, you build a main entrance with a receptionist (Ingress)
The receptionist reads the signs (rules) and sends people to the right shop based on what they ask.

🧩 Components Involved

Ingress Resource
A YAML config where you define rules like:
"If the request is for example.com/shop1, send it to service A"
"Use HTTPS with this certificate"

Ingress Controller
The software that actually reads the Ingress resource and does the routing . Examples: NGINX, Traefik, HAProxy, AWS ALB Controller .

// STEPS to apply ingress
There is multiple source/way to apply ingress . One is through nginx ingress controller . Just search on web 
kind cluster nginx ingress controller , and go to official website , from there , you can copy command to get ingress
controller from web . 

URL : https://kind.sigs.k8s.io/docs/user/ingress
Command : kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/usage.yaml

After this command , you can run , kubectl get ns .
There will new namespace will be created in the name of ingress-nginx . 

when you run kubectl get service -n ingress-nginx , there is seperate service file present . 
Now just you need to create ingress.yml file . Content of this file , can be copied from basic-file folder ingress.yml file . 

then run command kubectl apply -f ingress.yml . 

All service should be in same namespace to redirect traffic . 

then run command .  
sudo -E kubectl port-forward service/ingress-nginx-controller -n ingress-nginx 8080:80 --address=0.0.0.0 .

because now all will be controll by ingress controller , that's why we need to run service file of ingress-nginx . 

You can get service file from kubectl get service -n ingress-nginx .


========================================================= StatefulSet , Config and Secrets ===============================================================================
==========================================================================================================================================================================

What is a StatefulSet?
In Kubernetes, a StatefulSet is a way to manage stateful applications. Stateful applications are those that need to keep track of state across different instances or restarts. Think of apps like databases, caches, or anything that needs to store data persistently.

The Key Features of StatefulSet:
Stable, Unique Network Identity:
Every pod in a StatefulSet has a unique and stable hostname. So even if the pod gets deleted or restarted, it keeps the same name (e.g., myapp-0, myapp-1, etc.).

Persistent Storage:
StatefulSets can automatically create persistent volumes for each pod. These volumes are tied to the pod, meaning even if the pod is deleted or rescheduled, it can still access the same storage.

Ordered Deployment and Scaling:
Pods in a StatefulSet are created and scaled in order. So if you're scaling up (adding more pods), Kubernetes will create them one by one, in sequence. Similarly, when scaling down, they are deleted in reverse order.

Pod Stability:
StatefulSet ensures that if a pod crashes and is recreated, it will be assigned the same network identity and storage, which helps maintain the application's state.

Example Use Cases:

Databases: Imagine running a database like MySQL or PostgreSQL. Each database pod needs a stable identity (like mysql-0, mysql-1) and persistent storage for its data. A StatefulSet makes sure each pod gets its own volume, and if a pod crashes, it can be restarted with the same identity and storage.

Message Queues: If you're running something like Kafka, which needs to maintain a log and state across its brokers, a StatefulSet helps make sure each broker maintains its identity and storage.

StatefulSet vs Deployment:

Deployment: In a regular Deployment, the pods are stateless. This means they can be replaced freely without worrying about maintaining any state between them (like serving requests without remembering anything from one instance to another).

StatefulSet: In contrast, StatefulSet is for stateful applications, where the pod's identity and state need to be preserved even if the pod crashes, gets rescheduled, or is replaced.

Simple Analogy:

Think of a StatefulSet like a group of mailboxes where each one has a unique address. You can add or remove mailboxes (pods), but no matter what happens, each mailbox still keeps its address and its contents (storage). If you lose a mailbox, the contents are saved in a storage unit (persistent volume), and when the mailbox is restored, it still has the same address and can access the same contents.


================== Config Map and Secrets  ====================================
ConfigMap:
A ConfigMap is a Kubernetes object used to store non-sensitive configuration data in key-value pairs.
It's useful for things like application settings, environment variables, or config files that your pods need.
ConfigMaps allow you to decouple configuration from application code, making it easier to update settings without changing the app itself.
Example: You might store a database URL or API keys that are not sensitive (e.g., DB_HOST=localhost).

Secret:
A Secret is like a ConfigMap, but specifically for sensitive data such as passwords, tokens, or certificates.
Secrets are stored in an encoded format (base64) and can be made available to your pods as environment variables or mounted as files.
They provide a more secure way of handling sensitive information compared to plain text ConfigMaps.
Example: Storing a password like DB_PASSWORD=supersecret in a Secret.

Key Differences:
ConfigMap: For non-sensitive configuration data (e.g., URLs, flags, settings).
Secret: For sensitive data that you want to protect (e.g., passwords, API keys).












